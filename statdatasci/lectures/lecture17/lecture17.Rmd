---
title: "Binomial and Poisson Distribution"
subtitle: "<br><br> STA35A: Statistical Data Science 1"
author: "Xiao Hui Tai"
date: November 2, 2022
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      # ratio: "16:9"
      # highlightLines: true
      # highlightStyle: solarized-light
      countIncrementalSlides: false
---


```{r child = "../setup.Rmd"}
```

```{css, echo = FALSE}
.tiny .remark-code { font-size: 70%; }
.small .remark-code { font-size: 80%; }
.tiny { font-size: 60%; }
.small { font-size: 80%; }
```


```{r packages, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
```


## Reminders/announcements

- HW 4 due tomorrow at 9pm

- HW 5 will be released on Friday (usual schedule)

- HW 6: released 11/14 (after Veteren's Day), due 11/21 (after midterm 2, which is on 11/18)

- HW 7: released 11/28 (after Thanksgiving), due 12/2 

---
## Midterm 1 feedback 
- Review and office hours

- Length 

- Coding by hand 

- Practice problems 

---

## Recap
--

- Common probability distributions

  - Bernoulli 
      - Theoretical properties: probability mass function, parameters, mean and variance 
      - Sampling and law of large numbers; effect of changing parameters 
  
  - Binomial
      - Theoretical properties: probability mass function, parameters, mean and variance 

---
## Today
- Common probability distributions

  - Binomial 
      - More on calculating binomial probabilities
      - Sampling and law of large numbers; effect of changing parameters 
  
  - Poisson
  
---

## Recall: Binomial random variable

- The **binomial distribution** gives us the probability of $X$ "successes" from a sequence of $n$ independent Bernoulli trials (size $n$). 

- The random variable $X$ is the number of "successes," out of n, e.g., the number of students, out of 3, that have recent e-cigarette use 

- The probability mass function is given by $P(X=x)=\begin{pmatrix} n \\ x \end{pmatrix}p^x(1-p)^{n-x}$

- For a binomial random variable with number of Bernoulli trials $n$ (size $n$) and probability of success $p$, $E(X) = np$ and $Var(X) = n(p)(1-p)$

---

## Case Study: E-Cigarettes

- The [CDC reports](https://www.cdc.gov/tobacco/data_statistics/fact_sheets/youth_data/tobacco_use/index.htm) that 19.6% of high school students have smoked e-cigarettes in the past 30 days. We'll round this to 20% for simplicity.

- $P(Y=1)=P(Smoker)=p=0.2$ and $P(Y=0)=0.8$

- Previously, we talked about an experiment with 3 Bernoulli trials
  
  - Random variable was the number of students, out of 3, who smoked e-cigarettes in the past 30 days

---
## More examples of calculating binomial probabilities 

- We might be interested in the probability that there is at least 1 student, out of 500, that has recent e-cigarette use. 

- This translates to $P(X \geq 1)$, where $X$ is the random variable representing the number of students, out of 500, with recent e-cigarette use. Here, $n = 500$ and $p = .2$

- Other probabilities that may be of interest include the probability that more than 2 students, out of 500, have recent e-cigarette use. 

Binomial distribution: $P(X = x)=\begin{pmatrix} n \\ x \end{pmatrix}p^x(1-p)^{n-x}$

- Quick trick: $P(X \geq 1) = 1 - P(X=0)$ (you either have no students with recent e-cigarette use, or one or more students with recent e-cigarette use)

- Similarly, $P(X > 2)=1-P(X=0)-P(X=1)-P(X=2)$ 


---
## More examples of calculating binomial probabilities 

Binomial distribution: $P(X = x)=\begin{pmatrix} n \\ x \end{pmatrix}p^x(1-p)^{n-x}$

We thus have

.small[
$$
\begin{aligned}
P(X \geq 1) & =1-P(X = 0) \\
&=1-\begin{pmatrix}500 \\ 0 \end{pmatrix} 0.2^0 (0.8)^{500-0} \\
&=1-0.8^{500} \\
&= 1\\
 P(X>2) & = 1-P(X=0)-P(X=1)-P(X=2) \\ 
 & = 1 - 0.8^{500} - \begin{pmatrix} 500 \\ 1 \end{pmatrix}0.2^1(0.8)^{500-1} - \begin{pmatrix} 500 \\ 2 \end{pmatrix}0.2^2(0.8)^{500-2} \\
 & = 1 - 0.8^{500} - 500(0.2)(0.8)^{500-1} - \frac{500!}{2!(500-2)!}0.2^2(0.8)^{500-2} \\
 & = 1 - 0.8^{500} - 500(0.2)(0.8)^{500-1} - \frac{500(500-1)}{2}0.2^2(0.8)^{500-2} \\
 & = 1
\end{aligned}
$$
]

---
## In R

- Given the large number of students (500), it is almost certain that at least 1 or 2 would have recent e-cigarette use. 

- We might be interested instead in $P(X \geq 100)$, the probability that at least four-fifths of the students have recent e-cigarette use

- As we can see, this quickly becomes intractable. Luckily, we can do this in R

```{r}
sum(dbinom(x = 100:500, size = 500, prob = .2))
```

- We can also use the `pbinom()` function, which gives us $P(X \leq x)$ directly
```{r}
1 - pbinom(q = 99, size = 500, prob = .2)
```

---
## Sampling from a binomial distribution in R

- Recall draws from the Bernoulli distribution:
  
  - For any value of $0 \leq p \leq 1$ (including .5), we can use the `rbinom()` function

  - `rbinom()` has the arguments `n, size, prob`, where `n` is the number of draws, and `prob` is the probability of success.
  
  - `size` is the "number of trials (zero or more)" -- for the Bernoulli distribution, we use `size = 1`. 
  
---
## Sampling from a binomial distribution in R

- For the binomial distribution, `size` is the number of Bernoulli trials; in the e-cigarette example, `size = 3`

- **NOTE**: we use $n$ to denote the number of Bernoulli trials; in R this is the `size` argument

Description | R
----|--
Number of draws/samples from Binomial | `n`
Number of Bernoulli trials, size $n$ | `size`
Probability of success, $p$ | `prob`

- It should now make sense that for draws from the Bernoulli distribution, we use the argument `size = 1`.

---
## Sampling from a binomial distribution in R

Example: 100 draws from the binomial distribution; each draw is made of 3 Bernoulli trials (size 3); probability of success = .2

```{r}
set.seed(0) # so results are reproducible 
inputP <- .2
binomDraws <- rbinom(n = 100, size = 3, prob = inputP)
binomDraws
```


---
## Sample mean  

- Recall: for a binomial random variable with number of trials $n$ and probability of success $p$, $E(X) = np$ and $Var(X) = n(p)(1-p)$

- In our example, $p = .2$, $n = 3$, so $E(X) = .6$ and $Var(X) = 3*.2*.8 = .48$

- We can calculate the sample mean from our sample of 100:
```{r}
mean(binomDraws)
```

---
## Law of Large Numbers again
As the sample size grows, the sample mean gets closer to the expected value, or population mean

.small[
```{r}
set.seed(0) # so results are reproducible 
binomDraws <- rbinom(n = 5000, size = 3, prob = .2)
myMeans <- data.frame(sampleSize = 1:5000, myMean = NA)
meanFun <- function(inputSampSize, outcomes) {
  return(mean(outcomes[1:inputSampSize]))
}
myMeans$myMean <- sapply(myMeans$sampleSize, meanFun, binomDraws)
head(myMeans)
tail(myMeans)
```
]
---
## Law of Large Numbers again 
.small[
```{r}
myMeans %>%
  ggplot(aes(x = sampleSize, y = myMean)) +
  geom_line() +
  labs(x = "Sample size",
       y = "Sample mean",
       title = "Illustration of law of large numbers for Binomial distribution\nn = 3, p = .2")
```
]


---

## Frequency distribution of e-cigarette smokers (from sampling)

- The frequency distribution from sampling from a binomial distribution should resemble the probability distribution of the binomial distribution

- Use `rbinom()` to get 5000 draws from the population 

- In R:
.small[
```{r}
set.seed(0) # so results are reproducible 
binomDraws <- rbinom(n = 5000, size = 3, prob = .2)
table(binomDraws)/5000
```
]

- Compare with the theoretical probabilities:
.small[
```{r}
dbinom(x = 0:3, size = 3, prob = .2)
```
]
---

## Frequency distribution of e-cigarette smokers 

```{r}
data.frame(binomDraws) %>%
  ggplot(aes(x = binomDraws)) + 
    geom_bar() +
    labs(x = "Number of Smokers",
         title = "5000 samples from Binomial(3, .2)")
```

---
## Varying the number of Bernoulli trials: 100 trials

.small[
```{r}
set.seed(0) # so results are reproducible 
binomDraws100 <- rbinom(n = 5000, size = 100, prob = .2)
data.frame(binomDraws100) %>%
  ggplot(aes(x = binomDraws100)) + 
    geom_bar() +
    labs(x = "Number of Smokers",
         title = "5000 samples from Binomial(100, .2)")
```
]
---
## Varying the number of Bernoulli trials: 500 trials

.small[
```{r}
set.seed(0) # so results are reproducible 
binomDraws500 <- rbinom(n = 5000, size = 500, prob = .2)
data.frame(binomDraws500) %>%
  ggplot(aes(x = binomDraws500)) + 
    geom_bar() +
    labs(x = "Number of Smokers",
         title = "5000 samples from Binomial(500, .2)")
```
]
---
## Frequency distribution of e-cigarette smokers varying number of Bernoulli trials

.small[
.pull-left[
```{r eval = FALSE}
data.frame(binomDraws) %>%
  bind_cols(size = 3) %>%
  bind_rows(
    data.frame(binomDraws100) %>%
      rename(binomDraws = binomDraws100) %>%
      bind_cols(size = 100)
  ) %>%
  bind_rows(
    data.frame(binomDraws500) %>%
      rename(binomDraws = binomDraws500) %>%
      bind_cols(size = 500)
  ) %>%
  ggplot(aes(x = binomDraws, 
             fill = as.factor(size))) +
    geom_histogram(binwidth = 1, position = "identity", alpha = .7) + 
    labs(
      x = "Number of smokers",
      y = "Frequency",
      title = "5000 samples each from Binomial(3, .2), Binomial(100, .2), Binomial(500, .2)",
      fill = "Size"
    )
```
]
]
.pull-right[
```{r echo = FALSE, out.width = "100%"}
data.frame(binomDraws) %>%
  bind_cols(size = 3) %>%
  bind_rows(
    data.frame(binomDraws100) %>%
      rename(binomDraws = binomDraws100) %>%
      bind_cols(size = 100)
  ) %>%
  bind_rows(
    data.frame(binomDraws500) %>%
      rename(binomDraws = binomDraws500) %>%
      bind_cols(size = 500)
  ) %>%
  ggplot(aes(x = binomDraws, 
                    fill = as.factor(size))) + 
    geom_histogram(binwidth = 1, position = "identity", alpha = .7) + 
    labs(
      x = "Number of smokers",
      y = "Frequency",
      title = "5000 samples each from \n Binomial(3, .2), Binomial(100, .2), Binomial(500, .2)",
      fill = "Size"
    )
```
]

---
## Frequency distribution of e-cigarette smokers varying probability of success

.small[
```{r }
set.seed(0) # so results are reproducible 
binomP.2 <- rbinom(n = 5000, size = 100, prob = .2)
binomP.5 <- rbinom(n = 5000, size = 100, prob = .5)
binomP.7 <- rbinom(n = 5000, size = 100, prob = .7)
```
]
```{r echo = FALSE, out.width = "60%"}
data.frame(binomP.2) %>%
  rename(outcome = binomP.2) %>%
  bind_cols(prob = .2) %>%
  bind_rows(
    data.frame(binomP.5) %>%
      rename(outcome = binomP.5) %>%
      bind_cols(prob = .5)
  ) %>%
  bind_rows(
    data.frame(binomP.7) %>%
      rename(outcome = binomP.7) %>%
      bind_cols(prob = .7)
  ) %>%
  ggplot(aes(x = outcome, 
                    fill = as.factor(prob))) +
    geom_histogram(binwidth = 1, position = "identity", alpha = .7) + 
    labs(
      x = "Number of smokers",
      y = "Frequency",
      title = "5000 samples each from \nBinomial(100, .2), Binomial(100, .5), Binomial(100, .7)",
      fill = "Prob"
    )
```



---
## Poisson distribution

- The Poisson distribution is often useful for estimating the **number of events in a large population over a unit of time**. 

- For example:
  - The number of people having heart attacks in New York City every year
  - The number of cars crossing an intersection per hour
  - The number of typos in a book 
  
- It is named after French mathematician Siméon Denis Poisson

---
## Poisson distribution
- Examples: The number of people having heart attacks in New York City every year

- This distribution involves a few key ingredients
  - There must be a **fixed interval** of time or space
  
  - Events happen with a **known average rate**, independently of time since the last event ("memoryless" property)
      - One person having a heart attack does not change the probability of when the next person will have a heart attack

- The parameter that defines a Poisson distributed random variable is the **rate**, often denoted by $\lambda$, where $\lambda > 0$

- The rate is the **average number of occurrences per unit of time**

- Often used to model rare events

---
## Probability mass function, mean and variance

- The probability mass function for a Poisson distributed random variable is $P(X = x) = \frac{\lambda^x e^{-\lambda}}{x!}$, defined over non-negative integer values of $x$

- Recall: n! (pronounced "n factorial") is shorthand for the recursive multiplication $n! = n(n - 1)(n - 2)\cdots (1)$. 

- The distribution has no upper limit, i.e., $x$ can take very large non-negative integer values 

- For a Poisson random variable, the mean, $E(X) = \lambda$, and the variance, $Var(X) = \lambda$

---
## Poisson probabilities  
- Like we saw before, we can use the probability mean function, $P(X = x) = \frac{\lambda^x e^{-\lambda}}{x!}$, to calculate probabilities of taking a certain value

- For $x = 2$ and $\lambda = 3$, we have 

$$
\begin{aligned}
P(X = 2) &= \frac{3^2 e^{-3}}{2!}  = \frac{9(e^{-3})}{2(1)}  = 0.2240418
\end{aligned}
$$
- In R:

```{r}
dpois(x = 2, lambda = 3)
```

- For large values of $x$, the probability is very small because of the large denominator

```{r}
dpois(x = 10, lambda = 3)
```

---
## Probability distribution
- In the same manner, we can derive the entire probability distribution

.tiny[
.pull-left[
```{r}
dpois(x = 0:10, lambda = 3)
```

```{r eval = FALSE}
data.frame(x = 0:10, y = dpois(0:10, lambda = 3)) %>%
  ggplot(aes(x = x, y = y)) + 
    geom_bar(stat = "identity") +
  labs(title = "Probability distribution of Poisson(3)",
       y = "P(X = x)")
```
]
]
.pull-right[
```{r echo = FALSE, out.width = "100%"}
data.frame(x = 0:10, y = dpois(0:10, lambda = 3)) %>%
  ggplot(aes(x = x, y = y)) + 
    geom_bar(stat = "identity") +
  labs(title = "Probability distribution of Poisson(3)",
       y = "P(X = x)")
```
]

---
## Probability distribution varying lambda

.small[
```{r}
data.frame(x = 0:30, y = dpois(0:30, lambda = 3), lambda = 3) %>%
  bind_rows(data.frame(x = 0:30, y = dpois(0:30, lambda = 10), lambda = 10)) %>%
  bind_rows(data.frame(x = 0:30, y = dpois(0:30, lambda = 20), lambda = 20)) %>%
    ggplot(aes(x = x, y = y, fill = as.factor(lambda))) + 
      geom_bar(stat = "identity", 
               position = "identity", 
               alpha = .5) +
    labs(title = "Probability distribution of \nPoisson(3), Poisson(10), Poisson(20)",
         y = "P(X = x)",
         fill = "Lambda")
```
]

---
## Sampling from Poisson distribution in R
- For any non-negative value of $\lambda$, we can simulate random draws using the `rpois()` function

- `rpois()` has the arguments `n, lambda`, where `n` is the number of draws from the distribution, and `lambda` is the mean.

```{r}
set.seed(0) # so results are reproducible 
inputLambda <- 3
poissonDraws <- rpois(n = 100, lambda = inputLambda)
poissonDraws
```

---
## Frequency distribution varying lambda

.small[
```{r }
set.seed(0) # so results are reproducible 
poissonL3 <- rpois(n = 5000, lambda = 3)
poissonL10 <- rpois(n = 5000, lambda = 10)
poissonL20 <- rpois(n = 5000, lambda = 20)
```
]

.tiny[
.pull-left[
```{r eval = FALSE}
data.frame(poissonL3) %>%
  rename(outcome = poissonL3) %>%
  bind_cols(lambda = 3) %>%
  bind_rows(
    data.frame(poissonL10) %>%
      rename(outcome = poissonL10) %>%
      bind_cols(lambda = 10)
  ) %>%
  bind_rows(
    data.frame(poissonL20) %>%
      rename(outcome = poissonL20) %>%
      bind_cols(lambda = 20)
  ) %>%
  ggplot(aes(x = outcome, 
                    fill = as.factor(lambda))) +
    geom_histogram(binwidth = 1, position = "identity", alpha = .7) + 
    labs(
      x = "Number of occurrences",
      y = "Frequency",
      title = "5000 samples each from \nPoisson(3), Poisson(10), Poisson(20)",
      fill = "Lambda"
    )
```
]
]
.pull-right[
```{r echo = FALSE, out.width = "100%"}
data.frame(poissonL3) %>%
  rename(outcome = poissonL3) %>%
  bind_cols(lambda = 3) %>%
  bind_rows(
    data.frame(poissonL10) %>%
      rename(outcome = poissonL10) %>%
      bind_cols(lambda = 10)
  ) %>%
  bind_rows(
    data.frame(poissonL20) %>%
      rename(outcome = poissonL20) %>%
      bind_cols(lambda = 20)
  ) %>%
  ggplot(aes(x = outcome, 
                    fill = as.factor(lambda))) +
    geom_histogram(binwidth = 1, position = "identity", alpha = .7) + 
    labs(
      x = "Number of occurrences",
      y = "Frequency",
      title = "5000 samples each from \nPoisson(3), Poisson(10), Poisson(20)",
      fill = "Lambda"
    )
```
]

---
## Summary

--

- Common probability distributions: Binomial and Poisson 

  - Theoretical properties: probability mass function, parameters, mean and variance, effect of varying parameters
  
  - Sampling and law of large numbers; effect of changing parameters 

  - R functions:
  
      - `d____()`, e.g., `dbinom()`: for densities (more accurately, for discrete random variables these are probability mass functions, $P(X = x)$)
      - `p____()`, e.g., `pbinom()`: for $P(X\leq x)$
      - `r____()`, e.g., `rbinom()`: for random sample
    
