<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Sample proportion and Confidence intervals</title>
    <meta charset="utf-8" />
    <meta name="author" content="Xiao Hui Tai" />
    <meta name="date" content="2024-11-22" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/default-fonts.css" rel="stylesheet" />
    <link href="libs/font-awesome/css/all.min.css" rel="stylesheet" />
    <link href="libs/font-awesome/css/v4-shims.min.css" rel="stylesheet" />
    <link href="libs/panelset/panelset.css" rel="stylesheet" />
    <script src="libs/panelset/panelset.js"></script>
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Sample proportion and Confidence intervals
]
.subtitle[
## <br><br> STA35A: Statistical Data Science 1
]
.author[
### Xiao Hui Tai
]
.date[
### November 22, 2024
]

---







layout: true
  
&lt;!-- &lt;div class="my-footer"&gt; --&gt;
&lt;!-- &lt;span&gt; --&gt;
&lt;!-- &lt;a href="https://datasciencebox.org" target="_blank"&gt;datasciencebox.org&lt;/a&gt; --&gt;
&lt;!-- &lt;/span&gt; --&gt;
&lt;!-- &lt;/div&gt;  --&gt;

---


&lt;style type="text/css"&gt;
.tiny .remark-code { font-size: 70%; }
.small .remark-code { font-size: 80%; }
.tiny { font-size: 60%; }
.small { font-size: 80%; }
&lt;/style&gt;





## Today
- Sampling distribution of the sample proportion

- Normal approximation to binomial

- Confidence intervals: 

  - Introduction and interpretation 
  
  - Construction using Central Limit Theorem 


---

## Example: Bernoulli data

Assume that 67% of the population has had a prior COVID infection. Define the variable `\(X_i\)` to take value 1 if the `\(i\)`th randomly sampled resident has been infected, and let it be 0 otherwise. Assume the samples are independent. 

What distribution does `\(X_i\)` follow? What are the parameters? What is the mean? What is the variance? 

--
- The random variable `\(X_i\)` follows a Bernoulli distribution. A Bernoulli random variable has mean `\(p\)` and variance `\(p(1- p)\)`. Here `\(p=0.67\)`.

--

For a random sample, the sample mean `\(\overline{x}=\hat{p}\)` is an **estimate** of this probability (fraction of 1's)

**Sample proportion** is `\(\hat{P} = \frac{1}{n}\sum_{i = 1}^n X_i\)`, where `\(X_i \sim\)` Bernoulli(p)


---

## Simulation: Prior Infections

- For repeated samples of residents, if we compute the proportion with prior infection in each, what values will we see? Will we get 0.67 each time?

- What is the effect of the sample size `\(n\)`?

---

## Simulation: Prior Infections

Again, we perform 10000 experiments where each time we sample from a Bernoulli distribution with `prob = 0.67` and different values of `n`.


``` r
set.seed(0)
n10 &lt;- t(replicate(n = 10000, rbinom(10, size = 1, prob = .67)))
n10 &lt;- rowMeans(n10)

set.seed(0)
n50 &lt;- t(replicate(n = 10000, rbinom(50, size = 1, prob = .67)))
n50 &lt;- rowMeans(n50)

set.seed(0)
n100 &lt;- t(replicate(n = 10000, rbinom(100, size = 1, prob = .67)))
n100 &lt;- rowMeans(n100)

set.seed(0)
n500 &lt;- t(replicate(n = 10000, rbinom(500, size = 1, prob = .67)))
n500 &lt;- rowMeans(n500)
```

---
## Simulation: Prior Infections

.small[
.pull-left[

``` r
data.frame(propCovid = n10, sampleSize = 10) %&gt;%
  bind_rows(
    data.frame(n50, sampleSize = 50) %&gt;%
      rename(propCovid = n50)
  ) %&gt;%
  bind_rows(
    data.frame(n100, sampleSize = 100) %&gt;%
      rename(propCovid = n100)
  )%&gt;%
  bind_rows(
    data.frame(n500, sampleSize = 500) %&gt;%
      rename(propCovid = n500)
  ) %&gt;%
  ggplot(aes(x = propCovid,
             fill = as.factor(sampleSize))) +
  geom_density(alpha = .5) +
  labs(x = "Proportion of people with prior infection",
       y = "Density",
       title = "Sampling distribution from Bernoulli(.67)",
       fill = "Sample size")  +
  scale_fill_viridis_d()
```
]
]

.pull-right[
&lt;img src="lecture21_files/figure-html/unnamed-chunk-5-1.png" width="100%" style="display: block; margin: auto;" /&gt;
]

---
## Sampling distribution of the sample proportion

- Sample proportion is the **same as the sample mean**, when the **distribution is Bernoulli**

- Sample proportion `\(\hat{P} = \frac{1}{n}\sum_{i = 1}^n X_i\)`, where `\(X_i \sim\)` Bernoulli(p)

---
## Earlier example  

Assume that 67% of the population has had a prior COVID infection. Define the variable `\(X_i\)` to take value 1 if the `\(i\)`th randomly sampled resident has been infected, and let it be 0 otherwise. Assume the samples are independent. 

- The random variable `\(X\)` is Bernoulli. A Bernoulli random variable has mean `\(p\)` and variance `\(p(1- p)\)`. Here `\(p=0.67\)`.

- The sample proportion that had a prior infection is just the fraction of 1's

- Sample mean defined as `\(\overline{X} = \frac{\sum_{i = 1}^n{X_i}}{n}\)`. When `\(X_i\)` is Bernoulli, it can only take the values 0 and 1, and the sample mean is the same as the sample proportion. `\(\overline{X} = \hat{P}\)`.


---
## Sampling distribution of the sample proportion

- Recall: the Central Limit Theorem does not restrict the distribution of the underlying `\(X_1, ..., X_n\)`  

- `\(\overline{X}  \approx N(\mu, \frac{\sigma^2}{n})\)` 

- We get the sampling distribution of the sample proportion for free!

- When `\(X_i \sim\)` Bernoulli(p), `\(\mu = p\)` and `\(\sigma^2 = p(1-p)\)`.

- By the Central Limit Theorem,
`\(\overline{X} = \hat{P} \approx N(p, \frac{p(1-p)}{n})\)` 


---
## Exercise
We ask a random sample of 435 people if they like cats. Assume that the probability that a randomly selected person likes cats is 75%. Let `\(X_i\)` be the Bernoulli random variable representing whether or not the `\(i\)`th person likes cats. What is the sampling distribution of the sample proportion? What is the probability that the sample proportion is smaller than .7? 




---
## Normal approximation to the Binomial distribution
- Consider `\(Y \sim\)` Binomial(n, p)

- As the number of trials increases, the binomial distribution becomes symmetric and bell-shaped

- For large `\(n\)`, `\(Y \approx N(np, np(1-p))\)`

- Commonly used rule of thumb: `\(np &gt; 5\)` and `\(n(1-p) &gt; 5\)`

- This approximation comes from the Central Limit Theorem: `\(\overline{X} = \hat{P} = \frac{\sum_{i = 1}^n{X_i}}{n} \approx N(p, \frac{p(1-p)}{n})\)` where `\(X_i \sim\)` Bernoulli(p).

- Now, `\(Y = \sum_{i = 1}^n{X_i} = n \overline{X}\)`

- By the rules for expectation and variance, `\(E(n\overline{X}) = nE(\overline{X}) = np\)` and `\(Var(n\overline{X}) = n^2 Var(\overline{X}) = np(1-p)\)`

---
## Exercise
We ask a random sample of 435 people if they like cats. Assume that the probability that a randomly selected person likes cats is 75%. 

Find the probability that at least 325 people like cats. 


---
## Exercise
We ask a random sample of 435 people if they like cats. Assume that the probability that a randomly selected person likes cats is 75%. 

Using a normal approximation, find the probability that at least 325 people like cats. 


---

## Course content 

1. Fundamentals of R
  - Overview of data types and structures
  - Data manipulation and data visualization tools  

2. Descriptive statistics for numerical and categorical data

3. Probability
  - Rules of probability computation; conditional probability
  - Basic probability models: Binomial, Normal and Poisson 

4. Statistical inference
  - Sampling distributions of sample mean and sample proportion
  - **Hypothesis testing and confidence intervals for population mean and population proportion**


---
## Estimation and testing

- **Estimation**: "guess" for the unknown parameter

  - **Point estimate**: "Best guess", or estimate, for the population parameter. "Based on a survey of 300 UC Davis students, we estimate that 50% of students ride bikes on campus."
  
  - **Interval estimate**: "Based on a survey of 300 UC Davis students, we are 95% confident that the proportion of students riding bikes on campus is (.45, .55)."

- **Testing**: evaluating whether our observed sample provides evidence against some claim about the population

  - "We reject the hypothesis that 10% of UC Davis students ride bikes on campus"


---

## Point estimates vs. confidence intervals

- **Point estimate**: single value

  - For example, the sample mean `\(\overline{X}\)` is often used as an estimator for the population mean `\(\mu\)`

  - In R: `mean()` calculates the estimate (sample statistic) from a given sample 

- Point estimates vs. confidence intervals: If you want to catch a fish, do you prefer a spear or a net?

.pull-left[
&lt;img src="img/spear.png" width="70%" style="display: block; margin: auto;" /&gt;
]
.pull-right[
&lt;img src="img/net.png" width="70%" style="display: block; margin: auto;" /&gt;
]

---

## Point estimates vs. confidence intervals

If you want to estimate a population parameter, do you prefer to report a range of values or a single value?

.pull-left[
&lt;img src="img/spear.png" width="400" style="display: block; margin: auto;" /&gt;
]
.pull-right[
&lt;img src="img/net.png" width="400" style="display: block; margin: auto;" /&gt;
]

---
## What is a Confidence Interval?
- Range of reasonable values that are intended to **contain the parameter of interest** with a certain **degree of confidence**

- Written as (point estimate - margin of error, point estimate + margin of error).

&lt;img src="img/ci2.png" width="40%" style="display: block; margin: auto;" /&gt;

- Accompanied by a **level of confidence** (often 95%)

- "We are 95% **confident** that the true population parameter falls within the interval (point estimate - margin of error, point estimate + margin of error)"

---
## Example: Approval ratings

&lt;img src="img/approval.png" width="70%" style="display: block; margin: auto;" /&gt;

.tiny[
Source: https://www.rasmussenreports.com/public_content/politics/biden_administration/prez_track_sep23
]

What is the population parameter of interest? What is the sample statistic?

--

**Population parameter**: Proportion of likely voters that strongly disapprove of President Biden (red line; alternatively, strongly approve (green line))

**Sample statistic**: Proportion based on 1500 likely voters (on a given day)

**95% confidence interval**: (37%, 43%) for strongly disapprove
---
## Example: Vaccine efficacy

&lt;img src="img/vaccine.png" width="45%" style="display: block; margin: auto;" /&gt;

"The uncertainty around a point estimate can be small or large. Scientists represent this uncertainty by calculating a range of possibilities, which they call a confidence interval."

---
## Elements and interpretation 

.pull-left[
&lt;img src="img/vaccine.png" width="75%" style="display: block; margin: auto;" /&gt;

"We are 95% **confident** that the true population parameter falls within the interval (.85, .95)."
]

.pull-right[
**Elements**:
- Confidence level
- Point estimate
- Lower bound
- Upper bound
]

**Interpretation**: If we were to **repeat this procedure** a large number of times, sampling and constructing confidence intervals in the same way, **95% of constructed intervals would contain the true population parameter**.

---
## Interpretation 
"We are 95% **confident** that the true population parameter falls within the interval (.85, .95)."

**Interpretation**: If we were to **repeat this procedure** a large number of times, sampling and constructing confidence intervals in the same way, **95% of constructed intervals would contain the true population parameter**.

- If we repeat the experiment 10,000 times, i.e., draw samples and construct 10,000 confidence intervals, we would expect 9,500 of these to contain the true population parameter 

- **Incorrect interpretation**: *Observed interval* has a 95% *probability* of containing the population parameter

- Do not confuse **confidence** with **probability**

- Once we **observe an interval** (collected a sample), there is no more variability. The observed interval either contains the population parameter, or it does not. 

---
## Confidence Level: Procedure, not Specific Realization 

- The **confidence level** reflects the measure of confidence in the **procedure** that led to the confidence interval

- In our fishing example, it is a statement about the properties of the net (e.g., size, quality) and your fishing technique. Once you've made an attempt (cast net into water), you either caught fish or did not. 

--

- Another analogy: a game of horseshoes

.pull-left[

**Correct**: Based on your throwing technique, 95% of the horseshoes you throw will encircle the stake

**Incorrect**: After you throw a horseshoe, it has a 95% *probability* of encircling the stake. It does not! It either encircles the stake or does not
]

.pull-right[
&lt;img src="img/horseshoes.jpg" width="100%" style="display: block; margin: auto;" /&gt;

.tiny[
Source: https://www.istockphoto.com/photo/pitching-horseshoes-gm140471913-3413882
]
]
---

## Constructing confidence intervals 

- Need to quantify the **variability of our sample statistic**

- Use the **sampling distribution of the sample mean**, which we derived using the **Central Limit Theorem**

- In the following results, assume independent samples and `\(n\)` large enough, so that the Central Limit Theorem holds

- Recall: z-scores corresponding to particular probabilities are often written as `\(z_p\)`, where `\(p\)` denotes the probability in the right tail, e.g., `\(z_{.025} \approx 1.96\)`
  - (These z-scores are called critical values)

---

## Confidence intervals using CLT 

- What we want: "If we were to **repeat this procedure** a large number of times, sampling and constructing confidence intervals in the same way, **95% of constructed intervals would contain the true population parameter**"

- Translates to P(CI contains true parameter) = .95

--

- **Set up**: 
  - `\(X_i\)` are independent and identically distributed with population mean `\(\mu\)` and variance `\(\sigma^2\)`
  - Want confidence interval for the unknown population parameter `\(\mu\)`
  - We use the sample mean, `\(\overline{X}\)`, constructed from a sample of size `\(n\)`, as an estimator for the population mean
  - Assume `\(n\)` is large


---
## Confidence intervals using CLT 

- Final ingredient: `\(\alpha\)`, which is the **significance level** 

  - **Confidence level** = `\(100(1 - \alpha)\)`%, i.e., a **95% confidence interval** will need `\(\alpha = .05\)`
  
  - P(CI contains true parameter) = `\(1 - \alpha\)`

- `\(z_{\frac{\alpha}{2}}\)` is the z-score corresponding to a probability of `\(\frac{\alpha}{2}\)` in the right tail
  - For `\(\alpha = .05\)`, `\(z_{\frac{\alpha}{2}}\)` is 1.96, i.e., `\(P(Z &gt; 1.96) \approx .025\)`.

---
## Confidence intervals using CLT 

- Consider the interval

`$$\left(\overline{X}-z_{\frac{\alpha}{2}}\frac{\sigma}{\sqrt{n}}, \overline{X}+z_{\frac{\alpha}{2}}\frac{\sigma}{\sqrt{n}} \right)$$`

- We will prove that P(CI contains true parameter) = `\(1 - \alpha\)`, i.e., `\(P(\overline{X}-z_{\frac{\alpha}{2}}\frac{\sigma}{\sqrt{n}} \leq \mu \leq \overline{X}+z_{\frac{\alpha}{2}}\frac{\sigma}{\sqrt{n}}) = 1 - \alpha\)`

- For simplicity, we will use `\(\alpha = .05\)`, and replace `\(z_{\frac{\alpha}{2}}\)` by 1.96 in the proof, but note that this will work for any `\(\alpha\)` between 0 and 1


---
## Proof 

---
## Summary
- Sampling distribution of the sample proportion: `\(\overline{X} = \hat{P} \approx N(p, \frac{p(1-p)}{n})\)` 

- Normal approximation to binomial: For `\(Y \sim\)` Binomial(n, p), when `\(np &gt; 5\)` and `\(n(1-p) &gt; 5\)`, `\(Y \approx N(np, np(1-p))\)`

- Confidence intervals: 

  - Introduction and interpretation 
  
  - Construction using Central Limit Theorem: `\(\left(\overline{x}-z_{\frac{\alpha}{2}}\frac{\sigma}{\sqrt{n}}, \overline{x}+z_{\frac{\alpha}{2}}\frac{\sigma}{\sqrt{n}} \right)\)`

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
