<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Poisson and Normal (Gaussian) Distribution</title>
    <meta charset="utf-8" />
    <meta name="author" content="Xiao Hui Tai" />
    <meta name="date" content="2022-11-04" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/default-fonts.css" rel="stylesheet" />
    <link href="libs/font-awesome/css/all.css" rel="stylesheet" />
    <link href="libs/font-awesome/css/v4-shims.css" rel="stylesheet" />
    <link href="libs/panelset/panelset.css" rel="stylesheet" />
    <script src="libs/panelset/panelset.js"></script>
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Poisson and Normal (Gaussian) Distribution
]
.subtitle[
## <br><br> STA35A: Statistical Data Science 1
]
.author[
### Xiao Hui Tai
]
.date[
### November 4, 2022
]

---





layout: true
  
&lt;!-- &lt;div class="my-footer"&gt; --&gt;
&lt;!-- &lt;span&gt; --&gt;
&lt;!-- &lt;a href="https://datasciencebox.org" target="_blank"&gt;datasciencebox.org&lt;/a&gt; --&gt;
&lt;!-- &lt;/span&gt; --&gt;
&lt;!-- &lt;/div&gt;  --&gt;

---

&lt;style type="text/css"&gt;
.tiny .remark-code { font-size: 70%; }
.small .remark-code { font-size: 80%; }
.tiny { font-size: 60%; }
.small { font-size: 80%; }
&lt;/style&gt;





## Reminders

- Lab 6 due on Monday, 9PM

- HW 5 will be released today

- Participation survey opens after class, closes Monday 9PM 

- Change in schedule for remaining homework:
    - HW 6: released 11/14 (after Veterans Day), due 11/21 (after midterm 2, which is on 11/18)
    
    - HW 7: released 11/28 (after Thanksgiving), due 12/2 


---
## Recap

--

- Common probability distributions: Binomial and Poisson 

  - Theoretical properties: probability mass function, parameters, mean and variance, effect of varying parameters
  
  - Sampling and law of large numbers; effect of changing parameters 

  - R functions:
  
      - `d____()`, e.g., `dbinom()`: for densities (more accurately, for discrete random variables these are probability mass functions, `\(P(X = x)\)`)
      - `p____()`, e.g., `pbinom()`: for `\(P(X\leq x)\)`
      - `r____()`, e.g., `rbinom()`: for random sample

---
## Today
- Common probability distributions

  - Poisson distribution 

  - Normal or Gaussian
     
---
## Recall: Poisson distribution

- The Poisson distribution is often useful for estimating the **number of events in a large population over a unit of time**. 

- For example: The number of people having heart attacks in New York City every year

- This distribution involves a few key ingredients
  - There must be a **fixed interval** of time or space
  
  - Events happen with a **known average rate**, independently of time since the last event ("memoryless" property)

- The parameter that defines a Poisson distributed random variable is the **rate**, often denoted by `\(\lambda\)`, where `\(\lambda &gt; 0\)`

- The rate is the **average number of occurrences per unit of time**

- Often used to model rare events

---
## Recall: Probability mass function, mean and variance

- The probability mass function for a Poisson distributed random variable is `\(P(X = x) = \frac{\lambda^x e^{-\lambda}}{x!}\)`, defined over non-negative integer values of `\(x\)`

- For a Poisson random variable, the mean, `\(E(X) = \lambda\)`, and the variance, `\(Var(X) = \lambda\)`

- We can calculate probabilities in R using `dpois()`, e.g.:


```r
dpois(x = 2, lambda = 3)
```

```
## [1] 0.2240418
```

---
## Probability distribution
- In the same manner, we can derive the entire probability distribution

.tiny[
.pull-left[

```r
dpois(x = 0:10, lambda = 3)
```

```
##  [1] 0.0497870684 0.1493612051 0.2240418077 0.2240418077
##  [5] 0.1680313557 0.1008188134 0.0504094067 0.0216040315
##  [9] 0.0081015118 0.0027005039 0.0008101512
```


```r
data.frame(x = 0:10, y = dpois(0:10, lambda = 3)) %&gt;%
  ggplot(aes(x = x, y = y)) + 
    geom_bar(stat = "identity") +
  labs(title = "Probability distribution of Poisson(3)",
       y = "P(X = x)")
```
]
]
.pull-right[
&lt;img src="lecture18_files/figure-html/unnamed-chunk-6-1.png" width="100%" style="display: block; margin: auto;" /&gt;
]

---
## Probability distribution varying lambda

.small[

```r
data.frame(x = 0:30, y = dpois(0:30, lambda = 3), lambda = 3) %&gt;%
  bind_rows(data.frame(x = 0:30, y = dpois(0:30, lambda = 10), lambda = 10)) %&gt;%
  bind_rows(data.frame(x = 0:30, y = dpois(0:30, lambda = 20), lambda = 20)) %&gt;%
    ggplot(aes(x = x, y = y, fill = as.factor(lambda))) + 
      geom_bar(stat = "identity", 
               position = "identity", 
               alpha = .5) +
    labs(title = "Probability distribution of \nPoisson(3), Poisson(10), Poisson(20)",
         y = "P(X = x)",
         fill = "Lambda")
```

&lt;img src="lecture18_files/figure-html/unnamed-chunk-7-1.png" width="60%" style="display: block; margin: auto;" /&gt;
]

---
## Sampling from Poisson distribution in R
- For any non-negative value of `\(\lambda\)`, we can simulate random draws using the `rpois()` function

- `rpois()` has the arguments `n, lambda`, where `n` is the number of draws from the distribution, and `lambda` is the mean.


```r
set.seed(0) # so results are reproducible 
inputLambda &lt;- 3
poissonDraws &lt;- rpois(n = 100, lambda = inputLambda)
poissonDraws
```

```
##   [1] 5 2 2 3 5 2 5 6 4 3 1 2 1 4 2 4 3 4 8 2 4 6 2 4 1 2 2 0 2 5
##  [31] 2 3 3 3 1 5 4 4 1 4 2 5 3 4 3 3 4 0 3 4 4 3 5 3 2 1 1 2 3 4
##  [61] 2 5 2 3 2 4 2 3 4 1 5 2 5 2 2 3 5 5 2 4 6 3 4 2 2 4 2 4 1 2
##  [91] 1 2 1 3 5 4 4 3 2 4
```

---
## Frequency distribution varying lambda

.small[

```r
set.seed(0) # so results are reproducible 
poissonL3 &lt;- rpois(n = 5000, lambda = 3)
poissonL10 &lt;- rpois(n = 5000, lambda = 10)
poissonL20 &lt;- rpois(n = 5000, lambda = 20)
```
]

.tiny[
.pull-left[

```r
data.frame(poissonL3) %&gt;%
  rename(outcome = poissonL3) %&gt;%
  bind_cols(lambda = 3) %&gt;%
  bind_rows(
    data.frame(poissonL10) %&gt;%
      rename(outcome = poissonL10) %&gt;%
      bind_cols(lambda = 10)
  ) %&gt;%
  bind_rows(
    data.frame(poissonL20) %&gt;%
      rename(outcome = poissonL20) %&gt;%
      bind_cols(lambda = 20)
  ) %&gt;%
  ggplot(aes(x = outcome, 
                    fill = as.factor(lambda))) +
    geom_histogram(binwidth = 1, position = "identity", alpha = .7) + 
    labs(
      x = "Number of occurrences",
      y = "Frequency",
      title = "5000 samples each from \nPoisson(3), Poisson(10), Poisson(20)",
      fill = "Lambda"
    )
```
]
]
.pull-right[
&lt;img src="lecture18_files/figure-html/unnamed-chunk-11-1.png" width="100%" style="display: block; margin: auto;" /&gt;
]



---
## Recall: Continuous random variables

- We saw continuous random variables earlier and how they differ from discrete random variables

&lt;img src="img/density.png" width="40%" style="display: block; margin: auto;" /&gt;

- A probability distribution for a discrete random variable is called a **probability mass function**; for a continuous random variable it is a **probability density functions**

- For a continuous random variable, the probability that the random variable takes on any exact value is zero. Instead, we think about probabilities in ranges. 

- `\(P(a \leq X \leq b)\)` is the area under the density function between `\(a\)` and `\(b\)`.

---
## Normal Distribution

- The **normal distribution** is an example of a continuous distribution

- It is a very important distribution and one of the primary inferential tools in statistics 

- Many natural phenomenon approximate the normal distribution, such as weight, height, blood pressure, annual rainfall

- The normal distribution is commonly called the *Gaussian distribution* after [Carl Friedrich Gauss](https://en.wikipedia.org/wiki/Carl_Friedrich_Gauss), who wrote down the equations governing it in the early 1800's. 

- It is also sometimes referred to as a *bell curve*, although there are other distributions that are symmetric and shaped like a bell

---

## Illustration: Shoe sizes 

- Thinking about shoe sizes is a nice formulation for the Gaussian distribution

- Mickle et al (2010 *Footwear Science*) showed the following bimodal distribution of shoe sizes in the US. 

&lt;img src="img/bimodalshoes.png" width="80%" style="display: block; margin: auto;" /&gt;

Note that standard shoe sizes are discrete.

---

## Illustration: Shoe sizes 

- Let `\(X\)` represent shoe size for wearers of men's shoes

- Here is a (hypothetical) probability distribution of shoe sizes of wearers of men's shoes.

&lt;img src="lecture18_files/figure-html/unnamed-chunk-14-1.png" width="60%" style="display: block; margin: auto;" /&gt;

---

## Illustration: Shoe sizes 

If we want to know the probability that a customer coming into a store wants a men's shoe size smaller than 9, we just add up the heights of the bars for shoe sizes 8.5 and smaller. We can do this for shoe sizes in any range and tabulate the full discrete distribution of shoe sizes.


&lt;img src="lecture18_files/figure-html/unnamed-chunk-15-1.png" width="60%" style="display: block; margin: auto;" /&gt;


---

## Smaller Shoes

.pull-left[

```
##  size probability
##   5.5      0.0001
##   6.0      0.0006
##   6.5      0.0012
##   7.0      0.0032
##   7.5      0.0081
##   8.0      0.0180
##   8.5      0.0334
##   9.0      0.0556
##   9.5      0.0805
##  10.0      0.1072
##  10.5      0.1202
```
]
.pull-right[

```
##  size probability
##  11.0      0.1326
##  11.5      0.1247
##  12.0      0.1109
##  12.5      0.0807
##  13.0      0.0550
##  13.5      0.0345
##  14.0      0.0182
##  14.5      0.0086
##  15.0      0.0050
##  15.5      0.0012
##  16.0      0.0004
```
]

The probability of a random men's shoe wearer having a shoe size less than 9 in this population is 0.0646.

What is the probability of shoe size 10-11.5?
---

## Moving to Continuous Distributions

- Now suppose we could get *really* well-fitting shoes, using quarter sizes (9, 9.25, 9.5, 9.75, ...) or even tenth sizes (9, 9.1, 9.2, ...), or shoes specifically made to fit your feet perfectly.

- As the number of sizes increases, the bar width becomes more narrow, and the graph approaches a smooth curve.

- We will use these smooth curves to describe the probability distributions of continuous random variables (e.g. a shoe size could be 9.50032)

.pull-left[
&lt;img src="lecture18_files/figure-html/normal-1.png" width="90%" style="display: block; margin: auto;" /&gt;
]
.pull-right[
This is a *probability density function*.
]
---
## Moving to Continuous Distributions

- The probability density function can be used to get the probability of any range of continuous shoe sizes we would like to investigate.

&lt;img src="lecture18_files/figure-html/unnamed-chunk-16-1.png" width="60%" style="display: block; margin: auto;" /&gt;

For example, we can calculate the probability a continuous shoe size is less than 9 (the shaded area).

---
## Moving to Continuous Distributions
&lt;img src="lecture18_files/figure-html/unnamed-chunk-17-1.png" width="40%" style="display: block; margin: auto;" /&gt;

- How do we find this area of interest?

- Calculus! `$$P(a \leq X \leq b)=\text{area between a and b below the curve}=\int_a^b f(x)dx$$` where `\(f(x)\)` represents the density curve
  - In this course, we will use R

---
## Normal Distribution

- The normal distribution is a **symmetric, bell-shaped** distribution

- It is characterized by the mean, `\(\mu\)`, and the standard deviation, `\(\sigma\)` (or variance, `\(\sigma^2\)`)

- For the normal distribution, the **density function** is given by  `$$f(x)=\frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{1}{2}\frac{(x-\mu)^2}{\sigma^2}}$$`

- The notation `\(N(\mu,\sigma^2)\)` is often used.

- The normal distribution with mean 0 and standard deviation 1 is called the **standard normal distribution**. It is commonly denoted `\(Z \sim N(0, 1)\)`. 

---
## Probability density function for Normal Distribution
- Like `dbinom()` and `dpois()`, `dnorm()` in R gives us the probability distribution 

- Here instead of `\(P(X = x)\)`, it is the **value of the probability density function**, `\(f(x)\)` on the previous slide, at values that we input

- `dnorm()` has arguments `x`, `mean` and `sd`, where `mean` and `sd` are the mean and standard deviation of the normal distribution that we want

- **Remember that `\(P(X = x) = 0\)` for a continuous random variable**; the value that `dnorm()` gives us is not a probability but the height of the density function

---
## Probability density function for Normal Distribution

```r
dnorm(x = -3:3, mean = 0, sd = 1)
```

```
## [1] 0.004431848 0.053990967 0.241970725 0.398942280 0.241970725
## [6] 0.053990967 0.004431848
```

.small[

```r
data.frame(x = c(-3, 3)) %&gt;%
  ggplot(aes(x)) +
  stat_function(fun = dnorm, args = list(mean = 0, sd = 1)) +
  labs(title = "Probability distribution of N(0, 1)",
       y = "f(x)")
```

&lt;img src="lecture18_files/figure-html/unnamed-chunk-19-1.png" width="60%" style="display: block; margin: auto;" /&gt;
]

---
## Normal Distribution varying mean 
- Which of the three distributions have means 0, 1, and 4?

&lt;img src="lecture18_files/figure-html/unnamed-chunk-20-1.png" width="60%" style="display: block; margin: auto;" /&gt;

---
## Normal Distribution varying standard deviation 
- Which has standard deviation 1, 2, and 4? 

&lt;img src="lecture18_files/figure-html/unnamed-chunk-21-1.png" width="60%" style="display: block; margin: auto;" /&gt;

---
## Calculating probabilities for the normal distribution

- We saw `pbinom()`, which gave us `\(P(X \leq x)\)` for the binomial distribution

- Similarly, `pnorm()` gives us `\(P(X \leq x)\)` for the normal distribution. The arguments are 
  - `q`, the vector of quantiles ( `\(x\)` in `\(P(X \leq x)\)` ); note that you can input multiple values at once, hence "vector"
  - `mean`, the mean `\(\mu\)` (default value 0)
  - `sd`, the standard deviation `\(\sigma\)` (default value 1)


```r
pnorm(0)
```

```
## [1] 0.5
```

---
## Calculating probabilities for our shoes example

Going back to our shoe size example, assume that men's shoe sizes follow a normal distribution with mean 11 and standard deviation 1.5, i.e., `\(N(\mu = 11,\sigma^2 = 1.5^2)\)`

What is the probability of shoe sizes less than 9? 


```r
pnorm(9, mean = 11, sd = 1.5)
```

```
## [1] 0.09121122
```

What is the probability of shoe sizes greater than 9? 


```r
1 - pnorm(9, mean = 11, sd = 1.5)
```

```
## [1] 0.9087888
```



---
## Calculating probabilities for our shoes example
What is the probability of shoe sizes less than 13? 


```r
pnorm(13, mean = 11, sd = 1.5)
```

```
## [1] 0.9087888
```

What is the probability of shoe size 10-11.5?
--

```r
pnorm(11.5, mean = 11, sd = 1.5) - pnorm(10, mean = 11, sd = 1.5)
```

```
## [1] 0.3780661
```

---
## Probabilities between two values

&lt;img src="img/stdnorm6.png" width="60%" style="display: block; margin: auto;" /&gt;

To get the probability that a random wearer of men's shoes would wear a size between 10 and 11.5, we take `pnorm(11.5, mean = 11, sd = 1.5) - pnorm(10, mean = 11, sd = 1.5)` to get the value 0.3780661.

---
## Sampling from Normal distribution in R
- Just like with the Bernoulli, binomial and Poisson distributions, we can simulate random draws from the normal distribution using the `rnorm()` function

- `rnorm()` has the arguments `n, mean, sd`, where `n` is the number of draws from the distribution, `mean` is the mean and `sd` is the standard deviation.


```r
set.seed(0) # so results are reproducible 
normalDraws &lt;- rnorm(n = 100, mean = 0, sd = 1)
head(normalDraws, 20)
```

```
##  [1]  1.262954285 -0.326233361  1.329799263  1.272429321
##  [5]  0.414641434 -1.539950042 -0.928567035 -0.294720447
##  [9] -0.005767173  2.404653389  0.763593461 -0.799009249
## [13] -1.147657009 -0.289461574 -0.299215118 -0.411510833
## [17]  0.252223448 -0.891921127  0.435683299 -1.237538422
```

---
## Frequency distribution varying mean and sd

.small[

```r
set.seed(0) # so results are reproducible 
normal1 &lt;- rnorm(n = 5000, mean = 3, sd = 2)
normal2 &lt;- rnorm(n = 5000, mean = 3, sd = 10)
normal3 &lt;- rnorm(n = 5000, mean = 11, sd = 1.5) # shoe size distribution 
```
]

&lt;img src="lecture18_files/figure-html/unnamed-chunk-30-1.png" width="60%" style="display: block; margin: auto;" /&gt;

---
## Frequency distribution varying mean and sd

.small[

```r
set.seed(0) # so results are reproducible 
normal1 &lt;- rnorm(n = 5000, mean = 3, sd = 2)
normal2 &lt;- rnorm(n = 5000, mean = 3, sd = 10)
normal3 &lt;- rnorm(n = 5000, mean = 11, sd = 1.5)
```
]

&lt;img src="lecture18_files/figure-html/unnamed-chunk-32-1.png" width="60%" style="display: block; margin: auto;" /&gt;

---
## More about the standard normal distribution

- Recall: standard normal distribution `\(Z \sim N(0, 1)\)`

- A normally distributed random variable can be expressed as a standard normal by **subtracting the mean and dividing by the standard deviation**; this process is called **standardization**

- `\(Y \sim N(\mu, \sigma^2)\)`

- `\(Z = \frac{Y - \mu}{\sigma}\)`

- `\(E\left(\frac{Y - \mu}{\sigma}\right) = \frac{1}{\sigma}[E(Y) - \mu] = 0\)`

- `\(Var\left(\frac{Y - \mu}{\sigma}\right) = \frac{1}{\sigma^2}[Var(Y)] = \frac{1}{\sigma^2}[\sigma^2] = 1\)`

- What we are essentially doing is **moving the location** (mean moves to 0) and **changing the scale** (standard deviation becomes 1)

---
## More about the standard normal distribution

- Earlier, we were interested in the probability of shoe sizes smaller than 13, and we calculated it using

.small[

```r
pnorm(13, mean = 11, sd = 1.5)
```

```
## [1] 0.9087888
```
]

- Let `\(Y\)` be the random variable denoting men's shoe sizes. Then `\(Y \sim N(11, 1.5^2)\)`.

.tiny[
$$
`\begin{aligned}
P(Y \leq 13) &amp;= P\left(\frac{Y - \mu_y}{\sigma_y} \leq \frac{13 - \mu_y}{\sigma_y} \right) \\
&amp;=P\left( Z \leq \frac{13-11}{1.5} \right) \\
&amp;=P(Z \leq \frac{2}{1.5})
\end{aligned}`
$$
]
.small[

```r
pnorm(2/1.5, mean = 0, sd = 1)
```

```
## [1] 0.9087888
```
]

---
## z-score
.tiny[
$$
`\begin{aligned}
P(Y \leq 13) &amp;= P\left(\frac{Y - \mu_y}{\sigma_y} \leq \frac{13 - \mu_y}{\sigma_y} \right) \\
&amp;=P\left( Z \leq \frac{13-11}{1.5} \right) \\
&amp;=P(Z \leq \frac{2}{1.5})
\end{aligned}`
$$
]

- The standardized value on the right-hand side, `\(\frac{13-11}{1.5}\)`, is known more generally as a z-score, where `\(z = \frac{x - \mu}{\sigma} = \frac{\text{value - mean}}{\text{standard deviation}}\)`

- The z-score is the **number of standard deviations above (positive z-scores) or below the mean (negative z-scores)**. To see this:

  - `\(x - \mu\)` is the number relative to the mean, e.g., shoe size 13 is 2 above the mean
  
  - Dividing the above by `\(\sigma\)` gives us the number of standard deviations above the mean, e.g., with our shoe size distribution having a standard deviation of 1.5, shoe size 13 is `\(\frac{2}{1.5} = 1.33\)` standard deviations above the mean

---
## z-score

.tiny[
$$
`\begin{aligned}
P(Y \leq 13) &amp;= P\left(\frac{Y - \mu_y}{\sigma_y} \leq \frac{13 - \mu_y}{\sigma_y} \right) \\
&amp;=P\left( Z \leq \frac{13-11}{1.5} \right) \\
&amp;=P(Z \leq \frac{2}{1.5})
\end{aligned}`
$$
]

- The *relative* positions of values in the original and standardized distributions stay the same, i.e., `\(P(Y \leq 13) = P(Z \leq \frac{2}{1.5})\)` 
  - Our size 13 (or value `\(\frac{2}{1.5}\)` standard deviations above the mean) remains the same relative to the rest of the distribution.

---
## Standardizing in R

Consider the samples we drew earlier from `\(N \sim (11, 1.5^2)\)`

.small[

```r
set.seed(0) # so results are reproducible 
normal3 &lt;- rnorm(n = 5000, mean = 11, sd = 1.5) # shoe size distribution 
standardizedNormal3 &lt;- (normal3 - 11)/1.5
```
]

&lt;img src="lecture18_files/figure-html/unnamed-chunk-36-1.png" width="60%" style="display: block; margin: auto;" /&gt;

---
## Standardizing in R
&lt;img src="lecture18_files/figure-html/unnamed-chunk-37-1.png" width="60%" style="display: block; margin: auto;" /&gt;

.small[

```r
sum(normal3 &lt;= 13)/length(normal3)
```

```
## [1] 0.9072
```

```r
sum(standardizedNormal3 &lt;= 2/1.5)/length(standardizedNormal3)
```

```
## [1] 0.9072
```
]

---
## Summary

- Common probability distributions: Normal

  - Theoretical properties: probability density function, parameters, mean and variance, effect of varying parameters
  
  - R functions:
  
      - `dnorm()` for densities 
      - `pnorm()` for `\(P(X\leq x)\)`
      - `rnorm()` for random sample
    
  - Standard normal distribution
  
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
